{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "from pyspark.sql import functions as F\n",
        "users = spark.createDataFrame(\n",
        "    [\n",
        "        (\"u1\", \"Berlin\"),\n",
        "        (\"u2\", \"Berlin\"),\n",
        "        (\"u3\", \"Munich\"),\n",
        "        (\"u4\", \"Hamburg\"),\n",
        "    ],\n",
        "    [\"user_id\", \"city\"]\n",
        ")\n",
        "orders = spark.createDataFrame(\n",
        "    [\n",
        "        (\"o1\", \"u1\", \"p1\", 2, 10.0),\n",
        "        (\"o2\", \"u1\", \"p2\", 1, 30.0),\n",
        "        (\"o3\", \"u2\", \"p1\", 1, 10.0),\n",
        "        (\"o4\", \"u2\", \"p3\", 5, 7.0),\n",
        "        (\"o5\", \"u3\", \"p2\", 3, 30.0),\n",
        "        (\"o6\", \"u3\", \"p3\", 1, 7.0),\n",
        "        (\"o7\", \"u4\", \"p1\", 10, 10.0),\n",
        "    ],\n",
        "    [\"order_id\", \"user_id\", \"product_id\", \"qty\", \"price\"]\n",
        ")\n",
        "products = spark.createDataFrame(\n",
        "    [\n",
        "        (\"p1\", \"Ring VOLA\"),\n",
        "        (\"p2\", \"Ring POROG\"),\n",
        "        (\"p3\", \"Ring TISHINA\"),\n",
        "    ],\n",
        "    [\"product_id\", \"product_name\"]\n",
        ")\n",
        "users.show()\n",
        "orders.show()\n",
        "products.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "revenue = orders.select(sum(orders[\"qty\"]*orders[\"price\"]))\n",
        "revenue.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "orders=orders.withColumn(\"revenue\", orders[\"qty\"]*orders[\"price\"])\n",
        "orders.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "orders=broadcast(orders).join(users, \"user_id\")\n",
        "orders=broadcast(orders).join(products, \"product_id\")\n",
        "\n",
        "orders.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "import pyspark.sql.functions as F\n",
        "metric_city = orders.groupBy(\"city\").agg(F.count(orders[\"order_id\"]).alias(\"orders_cnt\"), F.sum(orders[\"qty\"]).alias(\"qty_sum\"), F.sum(orders[\"revenue\"]).alias(\"revenue_sum\"))\n",
        "metric_city.show()\n",
        "\n",
        "metric_product_id = orders.groupBy(\"product_id\").agg(F.count(orders[\"order_id\"]).alias(\"orders_cnt\"), F.sum(orders[\"qty\"]).alias(\"qty_sum\"), F.sum(orders[\"revenue\"]).alias(\"revenue_sum\"))\n",
        "metric_product_id.show()\n",
        "\n",
        "metric_product_name = orders.groupBy(\"product_name\").agg(F.count(orders[\"order_id\"]).alias(\"orders_cnt\"), F.sum(orders[\"qty\"]).alias(\"qty_sum\"), F.sum(orders[\"revenue\"]).alias(\"revenue_sum\"))\n",
        "metric_product_name.show()\n",
        "\n",
        "metric = orders.groupBy(\"city\", \"product_id\", \"product_name\").agg(F.count(orders[\"order_id\"]).alias(\"orders_cnt\"), F.sum(orders[\"qty\"]).alias(\"qty_sum\"), F.sum(orders[\"revenue\"]).alias(\"revenue_sum\"))\n",
        "metric.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number, desc\n",
        "funk = Window.partitionBy(\"city\").orderBy(desc(\"revenue_sum\"))\n",
        "\n",
        "top2 = metric.withColumn(\"rn\", row_number().over(funk)).filter(\"rn<3\").drop(\"rn\")\n",
        "top2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "path = \"hdfs:///tmp/sandbox_zeppelin/mart_city_top_products/\"\n",
        "top2.write.mode(\"overwrite\").parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "spark.read.parquet(path).show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "python",
      "pygments_lexer": "scala",
      "version": "3.13.9"
    },
    "name": "Revina DZ1"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
