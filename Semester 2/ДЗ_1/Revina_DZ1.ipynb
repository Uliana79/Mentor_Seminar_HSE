{
  "metadata": {
    "name": "Revina DZ1",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\r\nfrom pyspark.sql import functions as F\r\nusers \u003d spark.createDataFrame(\r\n    [\r\n        (\"u1\", \"Berlin\"),\r\n        (\"u2\", \"Berlin\"),\r\n        (\"u3\", \"Munich\"),\r\n        (\"u4\", \"Hamburg\"),\r\n    ],\r\n    [\"user_id\", \"city\"]\r\n)\r\norders \u003d spark.createDataFrame(\r\n    [\r\n        (\"o1\", \"u1\", \"p1\", 2, 10.0),\r\n        (\"o2\", \"u1\", \"p2\", 1, 30.0),\r\n        (\"o3\", \"u2\", \"p1\", 1, 10.0),\r\n        (\"o4\", \"u2\", \"p3\", 5, 7.0),\r\n        (\"o5\", \"u3\", \"p2\", 3, 30.0),\r\n        (\"o6\", \"u3\", \"p3\", 1, 7.0),\r\n        (\"o7\", \"u4\", \"p1\", 10, 10.0),\r\n    ],\r\n    [\"order_id\", \"user_id\", \"product_id\", \"qty\", \"price\"]\r\n)\r\nproducts \u003d spark.createDataFrame(\r\n    [\r\n        (\"p1\", \"Ring VOLA\"),\r\n        (\"p2\", \"Ring POROG\"),\r\n        (\"p3\", \"Ring TISHINA\"),\r\n    ],\r\n    [\"product_id\", \"product_name\"]\r\n)\r\nusers.show()\r\norders.show()\r\nproducts.show()\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nrevenue \u003d orders.select(sum(orders[\"qty\"]*orders[\"price\"]))\nrevenue.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\norders\u003dorders.withColumn(\"revenue\", orders[\"qty\"]*orders[\"price\"])\norders.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\norders\u003dbroadcast(orders).join(users, \"user_id\")\norders\u003dbroadcast(orders).join(products, \"product_id\")\n\norders.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nimport pyspark.sql.functions as F\nmetric_city \u003d orders.groupBy(\"city\").agg(F.count(orders[\"order_id\"]).alias(\"orders_cnt\"), F.sum(orders[\"qty\"]).alias(\"qty_sum\"), F.sum(orders[\"revenue\"]).alias(\"revenue_sum\"))\nmetric_city.show()\n\nmetric_product_id \u003d orders.groupBy(\"product_id\").agg(F.count(orders[\"order_id\"]).alias(\"orders_cnt\"), F.sum(orders[\"qty\"]).alias(\"qty_sum\"), F.sum(orders[\"revenue\"]).alias(\"revenue_sum\"))\nmetric_product_id.show()\n\nmetric_product_name \u003d orders.groupBy(\"product_name\").agg(F.count(orders[\"order_id\"]).alias(\"orders_cnt\"), F.sum(orders[\"qty\"]).alias(\"qty_sum\"), F.sum(orders[\"revenue\"]).alias(\"revenue_sum\"))\nmetric_product_name.show()\n\nmetric \u003d orders.groupBy(\"city\", \"product_id\", \"product_name\").agg(F.count(orders[\"order_id\"]).alias(\"orders_cnt\"), F.sum(orders[\"qty\"]).alias(\"qty_sum\"), F.sum(orders[\"revenue\"]).alias(\"revenue_sum\"))\nmetric.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import row_number, desc\nfunk \u003d Window.partitionBy(\"city\").orderBy(desc(\"revenue_sum\"))\n\ntop2 \u003d metric.withColumn(\"rn\", row_number().over(funk)).filter(\"rn\u003c3\").drop(\"rn\")\ntop2.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\npath \u003d \"hdfs:///tmp/sandbox_zeppelin/mart_city_top_products/\"\ntop2.write.mode(\"overwrite\").parquet(path)"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nspark.read.parquet(path).show()"
    }
  ]
}